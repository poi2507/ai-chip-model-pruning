# 사전 기술 검증 (Proof of Concept) 요약

### 제출 목적: 왜 이 자료를 준비했는가?

본 첨부 자료는 제안서의 성공적인 완수를 보장하기 위해, 핵심 기술의 실현 가능성과 제안자의 실행 역량을 선제적으로 입증하고자 제출합니다.

-   **기술적 타당성 입증:** 제안서에서 제시한 One-shot 프루닝 기법이 실제 LLM에 효과적으로 적용 가능함을 실험 데이터로 증명합니다.
-   **수행 능력 증명:** 제안자가 최신 경량화 기술을 직접 구현하고 분석할 수 있는 높은 수준의 기술 역량을 보유하고 있음을 보여줍니다.
-   **프로젝트 신뢰도 제고:** 사전 검증을 통해 본 프로젝트의 시행착오를 줄이고, 최종 목표 달성 가능성에 대한 신뢰를 높입니다.

---
### 사전 연구 개요: 무엇을 검증했는가?

제안서의 핵심 방법론을 Google Colab Pro의 고성능 GPU 환경에서 사전 테스트하고, 그 결과를 정량적으로 분석했습니다.

#### 검증 대상 기술
- 최신 One-shot 프루닝 3종: **SparseGPT, Wanda, FLAP**

#### 테스트 환경
- **하드웨어:** Google Colab Pro (NVIDIA A100 GPU)
- **소프트웨어:** PyTorch, Transformers, Hugging Face 등 표준 라이브러리
- **대상 모델:** 분석 환경과 모델의 성능을 고려해 **meta-llama/Llama-3.1-8B-Instruct** 모델

#### 핵심 검증 지표: 정확도 보존 능력 (Accuracy Preservation)
- **Perplexity (PPL):** 언어 모델의 일반적인 성능을 측정하여, 프루닝 후 성능 저하가 얼마나 적은지 확인합니다.
- **MMLU:** 종합적인 추론 능력을 평가하는 표준 벤치마크 점수를 통해, 모델의 핵심 지능이 유지되는지 검증합니다.

#### 실행 속도를 제외한 이유
- 프루닝으로 인한 추론 속도 향상은 0의 값을 건너뛰고 계산하는 희소 행렬 연산(예: NVIDIA의 2:4 Structured Sparsity)을 지원하는 전용 하드웨어(NPU, GPU Tensor Core 등)에서 발현됩니다.
- 본 사전 테스트는 알고리즘의 **압축 및 정확도 보존 능력 검증**에 집중하였으며, 실제 속도 측정은 타겟 NPU 환경의 본 실험에서 정밀하게 진행할 예정입니다.
